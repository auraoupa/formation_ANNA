/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:38688'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:42900'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:39083'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:38906'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:41478'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:36432'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:40655'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:39714'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:33978'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:37841'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:44159'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:34171'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:37682'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:45487'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:41822'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:34178'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:33025'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:33570'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:45385'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:39759'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:40331'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:38983'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:40078'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:38313'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:34433'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:42680'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:43311'
distributed.nanny - INFO -         Start Nanny at: 'tcp://172.30.10.144:42096'
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-iz4md45k', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qiamuuk3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-us0n3dre', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fqjos1p6', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tiu083no', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7y64ofns', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-lz2v58e6', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-b6ow283l', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-72rhleai', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ymafxkiv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-cm7s3ail', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-uiw5zftw', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-zc9x1coq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9vj2l2ak', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-o19krbu3', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-skfc6s7n', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vnu_bj1m', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6oa3tg3v', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-l3d2k4bc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-4uee3ctp', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-o5bfjm8p', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-q3sd_h9e', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fra8zgzc', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ia05h7jq', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-baq2r3ct', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-cb_5xwdi', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bi7ib0b8', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dsfd99um', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-dlgfggal', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-bw7_flkn', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8h8basc9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6s1j7zr4', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jq4ndv2i', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-p7u4w8ky', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-wiveabyh', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-93jtefma', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-tn714g5c', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-li6rd4zy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-octc4ddp', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-ltybp39m', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fcw080pb', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8cytaiv6', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-e5ujeq_9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-s0gxm08j', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-y1exnh7q', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0g65sskg', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-o8cr5_vd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xa7foldy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9g0dk4i5', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-lmark5sd', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6rg8e82d', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-vtszkxjv', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-pr2tiqiy', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-8yhx0lr9', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-uwuv2iy2', purging
distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-gnwdypnl', purging
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:45861
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:46507
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:45861
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:42276
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:46507
distributed.worker - INFO -          dashboard at:        172.30.10.144:46691
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:37055
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:42276
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:41052
distributed.worker - INFO -          dashboard at:        172.30.10.144:33249
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:44306
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:37055
distributed.worker - INFO -          dashboard at:        172.30.10.144:46425
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:41052
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:44306
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        172.30.10.144:45793
distributed.worker - INFO -          dashboard at:        172.30.10.144:35098
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:        172.30.10.144:35919
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-i4p3ah0p
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-c5pu_uc8
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6b93q_b_
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-jy_lvguk
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-sq50dagv
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-5_qmw05g
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:42606
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:42606
distributed.worker - INFO -          dashboard at:        172.30.10.144:38849
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-nf76nfir
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:46009
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:46009
distributed.worker - INFO -          dashboard at:        172.30.10.144:38441
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-texg7oyo
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:45445
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:45445
distributed.worker - INFO -          dashboard at:        172.30.10.144:42059
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-f74888f3
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:46795
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:46795
distributed.worker - INFO -          dashboard at:        172.30.10.144:37811
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-qrdl76nv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:45311
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:45311
distributed.worker - INFO -          dashboard at:        172.30.10.144:35997
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-xs6hsdf_
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/contextlib.py:119: UserWarning: Creating scratch directories is taking a surprisingly long time. This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.
  next(self.gen)
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:36082
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:36082
distributed.worker - INFO -          dashboard at:        172.30.10.144:43316
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-3k06vlme
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:44339
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:44339
distributed.worker - INFO -          dashboard at:        172.30.10.144:43333
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:43663
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-x9y4t_lt
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:43663
distributed.worker - INFO -          dashboard at:        172.30.10.144:32997
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-m11r7zqo
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:40076
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:40076
distributed.worker - INFO -          dashboard at:        172.30.10.144:34293
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-i9zp8s45
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:37362
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:37362
distributed.worker - INFO -          dashboard at:        172.30.10.144:34063
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-0tg7inuv
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:41368
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:41368
distributed.worker - INFO -          dashboard at:        172.30.10.144:34391
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-7elqzm7v
distributed.worker - INFO - -------------------------------------------------
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:42028
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:42028
distributed.worker - INFO -          dashboard at:        172.30.10.144:33714
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6rmnu642
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:34675
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:34675
distributed.worker - INFO -          dashboard at:        172.30.10.144:33272
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_d4yttd7
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:43501
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:43501
distributed.worker - INFO -          dashboard at:        172.30.10.144:35597
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-s7y9vixi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:36608
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:36608
distributed.worker - INFO -          dashboard at:        172.30.10.144:39587
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-h8vbpv40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:37666
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:37666
distributed.worker - INFO -          dashboard at:        172.30.10.144:33869
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-__g1gzrm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:44237
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:44237
distributed.worker - INFO -          dashboard at:        172.30.10.144:43425
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-fcrzqhv6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:45574
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:45574
distributed.worker - INFO -          dashboard at:        172.30.10.144:41100
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-6y6jaw7j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:34092
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:34092
distributed.worker - INFO -          dashboard at:        172.30.10.144:39493
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-_yk8trqt
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:44582
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:44582
distributed.worker - INFO -          dashboard at:        172.30.10.144:41869
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-9chnyqfh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:44806
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:44806
distributed.worker - INFO -          dashboard at:        172.30.10.144:44293
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-rki8cntc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
distributed.worker - INFO -       Start worker at:  tcp://172.30.10.144:36337
distributed.worker - INFO -          Listening to:  tcp://172.30.10.144:36337
distributed.worker - INFO -          dashboard at:        172.30.10.144:41550
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.29 GB
distributed.worker - INFO -       Local Directory: /scratch/cnt0024/hmg2840/albert7a/daskjobqueue/worker-26co7p0p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://172.30.100.3:41851
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
distributed.utils_perf - INFO - full garbage collection released 15.72 MB from 2108 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 15.71 MB from 2142 reference cycles (threshold: 10.00 MB)
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
distributed.utils_perf - INFO - full garbage collection released 63.75 MB from 1470 reference cycles (threshold: 10.00 MB)
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
distributed.utils_perf - INFO - full garbage collection released 15.72 MB from 1854 reference cycles (threshold: 10.00 MB)
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
distributed.utils_perf - INFO - full garbage collection released 19.76 MB from 1529 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.84 MB from 1734 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 16.00 MB from 1335 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.68 MB from 1931 reference cycles (threshold: 10.00 MB)
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
distributed.utils_perf - INFO - full garbage collection released 79.61 MB from 2010 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 15.64 MB from 2297 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 71.55 MB from 1729 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.81 MB from 2438 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.77 MB from 1942 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 79.50 MB from 2192 reference cycles (threshold: 10.00 MB)
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
distributed.utils_perf - INFO - full garbage collection released 87.76 MB from 1557 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 23.62 MB from 1781 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 43.99 MB from 1763 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 43.54 MB from 1746 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 20.01 MB from 2042 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 119.26 MB from 1824 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 17.14 MB from 2191 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 67.01 MB from 1705 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 18.65 MB from 1573 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.60 MB from 1016 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 35.99 MB from 2079 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.81 MB from 1711 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 847.97 MB from 1387 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 396.01 MB from 1288 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 39.68 MB from 1826 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.85 MB from 2166 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 356.01 MB from 2187 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.76 MB from 1611 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 24.00 MB from 1882 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.67 MB from 1728 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 139.99 MB from 1710 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 292.14 MB from 2076 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 19.62 MB from 1910 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - Connection to scheduler broken.  Reconnecting...
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://172.30.100.3:41851' processes=56 cores=56>>
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/client.py", line 1077, in _heartbeat
    self.scheduler_comm.send({"op": "heartbeat-client"})
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/batched.py", line 119, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://172.30.100.3:41851' processes=56 cores=56>>
Traceback (most recent call last):
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py", line 907, in _run
    return self.callback()
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/client.py", line 1077, in _heartbeat
    self.scheduler_comm.send({"op": "heartbeat-client"})
  File "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/batched.py", line 119, in send
    raise CommClosedError
distributed.comm.core.CommClosedError
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.client - ERROR - Failed to reconnect to scheduler after 3.00 seconds, closing client
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.utils_perf - INFO - full garbage collection released 18.96 MB from 3884 reference cycles (threshold: 10.00 MB)
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Comm closed
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - INFO - Waiting to connect to:   tcp://172.30.100.3:41851
distributed.worker - ERROR - Timed out when connecting to scheduler 'tcp://172.30.100.3:41851'
NoneType: None
distributed.worker - INFO - Stopping worker at tcp://172.30.10.144:36082
distributed.nanny - INFO - Closing Nanny at 'tcp://172.30.10.144:38906'
distributed.dask_worker - INFO - End worker
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
distributed.process - WARNING - reaping stray process <ForkServerProcess(Dask Worker process (from Nanny), started daemon)>
/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/utils.py:136: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable
  RuntimeWarning,
