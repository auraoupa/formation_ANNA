{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/bokeh/core.py:74: UserWarning: \n",
      "Failed to start diagnostics server on port 8787. [Errno 13] Permission denied\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41967\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:36903/status' target='_blank'>http://127.0.0.1:36903/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>48</li>\n",
       "  <li><b>Memory: </b>118.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:41967' processes=8 cores=48>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "import dask.threaded\n",
    "import dask.multiprocessing\n",
    "from dask.distributed import Client\n",
    "\n",
    "c = Client()\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/xarray/core/merge.py:16: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)\n"
     ]
    }
   ],
   "source": [
    "##imports\n",
    "\n",
    "import xarray as xr \n",
    "import dask \n",
    "import numpy as np \n",
    "import os \n",
    "import time \n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "today=datetime.date.today()\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/home/albert7a/git/xscale')\n",
    "import xscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data location and gridfile\n",
    "\n",
    "data_dir = '/store/CT1/hmg2840/lbrodeau/eNATL60/eNATL60-BLBT02-S/'\n",
    "gridfile='/store/CT1/hmg2840/lbrodeau/eNATL60/eNATL60-I/mesh_mask_eNATL60_3.6_lev1.nc4'\n",
    "dsgrid=xr.open_dataset(gridfile,chunks={'x':1000,'y':1000})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## box indices \n",
    "def read_csv(box):\n",
    "    boxes=pd.read_csv('/home/albert7a/git/formation_ANNA/make_boxes/boxes_'+str(box)+'_1x1_eNATL60.csv',sep = '\\t',index_col=0)\n",
    "    imin=boxes['imin']\n",
    "    imax=boxes['imax']\n",
    "    jmin=boxes['jmin']\n",
    "    jmax=boxes['jmax']\n",
    "    box_name=boxes.index\n",
    "    return imin,imax,jmin,jmax,box_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions useful for computations\n",
    "\n",
    "def dx_var(data,e1):\n",
    "    dx_var = (data.shift(x=-1) - data)/e1\n",
    "    return dx_var\n",
    "def dy_var(data,e2):\n",
    "    dy_var = (data.shift(y=-1) - data)/e2\n",
    "    return dy_var\n",
    "def dz_var(data,e3,dimdep):\n",
    "    if dimdep == 'deptht':\n",
    "        dz_var = (data.shift(deptht=-1) - data)/e3\n",
    "    if dimdep == 'depthu':\n",
    "        dz_var = (data.shift(depthu=-1) - data)/e3\n",
    "    if dimdep == 'depthv':\n",
    "        dz_var = (data.shift(depthv=-1) - data)/e3\n",
    "    if dimdep == 'depthw':\n",
    "        dz_var = (data.shift(depthw=-1) - data)/e3\n",
    "    return dz_var\n",
    "\n",
    "\n",
    "def compute_buoy(t,s):\n",
    "    rau0  = 1000\n",
    "    grav  = 9.81\n",
    "    buoy= -1*(grav/rau0)*sigma0(t,s)\n",
    "    return buoy\n",
    "\n",
    "def sigma0(t,s):\n",
    "    zrau0=1000\n",
    "    zsr=np.sqrt(np.abs(s))\n",
    "    zs=s\n",
    "    zt=t\n",
    "    zr1 = ( ( ( ( 6.536332e-9*zt-1.120083e-6 )*zt+1.001685e-4)*zt - 9.095290e-3 )*zt+6.793952e-2 )*zt+999.842594\n",
    "    zr2= ( ( ( 5.3875e-9*zt-8.2467e-7 )*zt+7.6438e-5 ) *zt - 4.0899e-3 ) *zt+0.824493\n",
    "    zr3= ( -1.6546e-6*zt+1.0227e-4 ) *zt-5.72466e-3\n",
    "    zr4= 4.8314e-4\n",
    "    sigma0=( zr4*zs + zr3*zsr + zr2 ) *zs + zr1 - zrau0\n",
    "    return sigma0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt(w):\n",
    "    win_box2D = w.window\n",
    "    win_box2D.set(window='hanning', cutoff=20, dim=['x', 'y'], n=[30, 30])\n",
    "    bw = win_box2D.boundary_weights(drop_dims=[])\n",
    "    w_LS = win_box2D.convolve(weights=bw)\n",
    "    w_SS=w-w_LS\n",
    "    return w_SS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correspondance of dimensions and grids for each variable\n",
    "filetyps = {'buoyancy' : 'gridT','votemper' : 'gridT', 'vosaline' : 'gridS','vozocrtx' : 'gridU', 'vomecrty' : 'gridV','vovecrtz' : 'gridW'}\n",
    "filedeps = {'buoyancy' : 'deptht','votemper' : 'deptht','vosaline' : 'deptht','vozocrtx' : 'depthu', 'vomecrty' : 'depthv','vovecrtz':'depthw'}\n",
    "filee1 = {'buoyancy' : 'e1t','votemper' : 'e1t','vosaline' : 'e1t','vozocrtx' : 'e1u', 'vomecrty' : 'e1v','vovecrtz':'e1f'}\n",
    "filee2 = {'buoyancy' : 'e2t','votemper' : 'e2t','vosaline' : 'e2t','vozocrtx' : 'e2u', 'vomecrty' : 'e2v','vovecrtz':'e2f'}\n",
    "filee3 = {'buoyancy' : 'e3t_0','votemper' : 'e3t_0','vosaline' : 'e3t_0','vozocrtx' : 'e3u_0', 'vomecrty' : 'e3v_0','vovecrtz':'e3w_0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main computation function\n",
    "def compute_profile(var,date,ibox,imin,imax,jmin,jmax,box_name):\n",
    "    if var == 'buoyancy':\n",
    "        filenameT = sorted(glob.glob(data_dir+'*/eNATL60-BLBT02_1h_*_gridT_'+date+'-'+date+'.nc'))\n",
    "        fileT=filenameT[0]\n",
    "        dsT=xr.open_dataset(fileT,chunks={'x':1000,'y':1000,'time_counter':1,'deptht':1})\n",
    "        dataT=dsT['votemper']\n",
    "        filenameS = sorted(glob.glob(data_dir+'*/eNATL60-BLBT02_1h_*_gridS_'+date+'-'+date+'.nc'))\n",
    "        fileS=filenameS[0]\n",
    "        dsS=xr.open_dataset(fileS,chunks={'x':1000,'y':1000,'time_counter':1,'deptht':1})\n",
    "        dataS=dsS['vosaline']\n",
    "        data=compute_buoy(dataT,dataS)\n",
    "        attrs=dataT.attrs\n",
    "        attrs['standard_name']='Buoyancy'\n",
    "        attrs['long_name']='Buoyancy'\n",
    "        attrs['units']='m/s2'\n",
    "    else:\n",
    "        filename = sorted(glob.glob(data_dir+'*/eNATL60-BLBT02_1h_*_'+filetyps[var]+'_'+date+'-'+date+'.nc'))\n",
    "        file=filename[0]\n",
    "        ds=xr.open_dataset(file,chunks={'x':1000,'y':1000,'time_counter':1,filedeps[var]:1})\n",
    "        data=ds[str(var)]\n",
    "        attrs=data.attrs\n",
    "        \n",
    "    filt_data=filt(data)\n",
    "    profile_data=filt_data[:,:,jmin[ibox]:jmax[ibox],imin[ibox]:imax[ibox]].mean(dim={'x','y','time_counter'})\n",
    "    return profile_data,attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_profile_all_var(date,ibox,profile_name,imin,imax,jmin,jmax,box_name):\n",
    "    list_dataset=[]\n",
    "    for var in ['votemper']:\n",
    "        print('compute mean profile of '+var)\n",
    "        profile_data,attrs=compute_profile(var,'20090701',0,imin,imax,jmin,jmax,box_name)\n",
    "        dataset=profile_data.to_dataset(name=var)\n",
    "        dataset[var].attrs=attrs\n",
    "        dataset[var].attrs['standard_name']=attrs['standard_name']\n",
    "        dataset[var].attrs['long_name']=attrs['long_name']\n",
    "        dataset[var].attrs['units']=attrs['units']\n",
    "        list_dataset.append(dataset)\n",
    "    print('merging all datasets')\n",
    "    big_dataset=xr.merge(list_dataset)\n",
    "    big_dataset.attrs['global_attribute']= 'predictors profiles averaged over 24h and in '+box_name[ibox]+' computed on occigen '+str(today)\n",
    "    print('writing to netcdf')\n",
    "    big_dataset.to_netcdf(path=profile_name,mode='w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = 'LS'\n",
    "k = 0\n",
    "date = '20090714'\n",
    "\n",
    "imin,imax,jmin,jmax,box_name=read_csv(box)\n",
    "profile_name='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLBT02-S/ANNA/'+str(box)+'/eNATL60'+str(box)+box_name[k]+'-BLBT02_y'+date[0:4]+'m'+date[4:6]+'d'+date[6:9]+'_profiles.nc'\n",
    "\n",
    "compute_profile_all_var(date,k,profile_name,imin,imax,jmin,jmax,box_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = 'LS'\n",
    "date = '20090714'\n",
    "\n",
    "for k in np.arange(0,):\n",
    "    compute_profile_all_var(date,k,profile_name,imin,imax,jmin,jmax,box_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
